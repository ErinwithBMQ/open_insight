import os
os.environ['GRADIO_TEMP_DIR'] = os.path.expanduser('~/.gradio/tmp')

import gradio as gr
from wordcloud import WordCloud
import os
from src.Function_annotations.utils import parse_text_to_json
from utils import parse_text_to_json1
import configparser
import time
import random
config = configparser.ConfigParser()
config.read('config.ini')


TMP_PATH = config.get('GLOBAL_PATHS', 'tmp_path', fallback='tmp')
FEATURE_FILE_PATH = os.path.join(TMP_PATH,"word_paradigm_generation")
FUNCTION_FILE_PATH = os.path.join(TMP_PATH,"function_annotations")
DOMAIN_FILE_PATH = "results"

class TextAnalysisApp:
    def __init__(self):
        self.path = TMP_PATH
        self.demo = self.build_interface()


    def word_paradigm_generation(self,input_text):
        sleep_time = random.randint(5, 8)
        time.sleep(sleep_time)
        feature_file_path = input_text.replace('https://github.com/', '').replace('https://gitee.com/', '').replace('/', '_')
        feature_file_path = os.path.join(FEATURE_FILE_PATH, feature_file_path)
        feature_file_name = os.path.join(feature_file_path, "output.txt")

        with open(feature_file_name, "r", encoding="utf-8") as f:
            feature_content = f.read()
        parsed_data = parse_text_to_json(feature_content)

        feature_words = parsed_data.get("æ‰€æœ‰ç‰¹å¾è¯æ±‡æ€»", [])
        domain_output = parsed_data.get("æŠ€æœ¯é¢†åŸŸåˆ†ç±»ç»“æœ", "").replace('*', '')
        keywords = feature_words
        freqs = [1] * len(feature_words)

        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color="white",
            font_path="/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # è®¾ç½®ä¸­æ–‡å­—ä½“è·¯å¾„
        ).generate_from_frequencies(dict(zip(feature_words, freqs)))
        wordcloud_path = r"img/wordcloud_first.png"
        wordcloud.to_file(wordcloud_path)

        self.top_keywords = "\n".join(keywords)

        return domain_output, wordcloud_path, self.top_keywords
        # pass


    def function_annotations(self, input_text):
        sleep_time = random.randint(5, 8)
        time.sleep(sleep_time)
        function_path = input_text.replace('https://github.com/', '').replace('https://gitee.com/', '').replace('/', '_')
        function_path = os.path.join(FUNCTION_FILE_PATH, function_path)
        function_path = os.path.join(function_path, "output.txt")
        with open(function_path, "r", encoding="utf-8") as f:
            # f.write(json.dumps(parsed_data, ensure_ascii=False, indent=4))
            summary = f.read().strip()
            summary = summary[summary.find("\n")+1:] if "\n" in summary else summary
            if not summary:
                summary = "æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åŠŸèƒ½æ³¨è§£ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡æœ¬æˆ–æ¨¡å‹é…ç½®ã€‚"
        return summary

    def domain_classification(self, input_text):
        '''
        result = {
            "å®é¢†åŸŸæŠ€æœ¯é¢†åŸŸ": "",
            "ç»†ç²’åº¦æŠ€æœ¯åˆ†ç±»": "",
            "ç‰¹å¾è¯ç»“æœ": [],
        '''
        sleep_time = random.randint(5, 8)
        time.sleep(sleep_time)
        domain_path = input_text.replace('https://github.com/', '').replace('https://gitee.com/', '').replace('/', '_')
        domain_path = os.path.join(DOMAIN_FILE_PATH, domain_path+".txt")
        # domain_path = os.path.join(domain_path, "output.txt")
        with open(domain_path, "r", encoding="utf-8") as f:
            domain_content = f.read()
        parsed_data = parse_text_to_json1(domain_content)

        feature_words1 = self.top_keywords + "\n".join(parsed_data.get("ç‰¹å¾è¯ç»“æœ", []))
        feature_words = feature_words1.split("\n")
        # print(feature_words)
        if len(feature_words) > 10:
            feature_words = feature_words[:10]
        freqs = [1] * len(feature_words)

        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color="white",
            font_path="/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # è®¾ç½®ä¸­æ–‡å­—ä½“è·¯å¾„
        ).generate_from_frequencies(dict(zip(feature_words, freqs)))
        wordcloud_path = r"img/wordcloud_first.png"
        wordcloud.to_file(wordcloud_path)

        # self.top_keywords = "\n".join(feature_words)



        return parsed_data.get("å®é¢†åŸŸæŠ€æœ¯é¢†åŸŸ", ""),parsed_data.get("ç»†ç²’åº¦æŠ€æœ¯åˆ†ç±»", ""),feature_words1,wordcloud_path


    def text_analysis(self, input_text):
        """ æ–‡æœ¬åˆ†æå¤„ç†å‡½æ•° """

        # ç”Ÿæˆè¯äº‘
        domain_output, wordcloud, top_keywords = self.word_paradigm_generation(input_text)
        # print("top_keywords:",top_keywords)


        # ç”ŸæˆåŠŸèƒ½æ³¨è§£
        summary = self.function_annotations(input_text)
        # print("summary:",summary)
        
        # è¿›è¡ŒæŠ€æœ¯é¢†åŸŸåˆ†ç±»
        domain_xiuzheng_output, xiaofeidu_output, feature,wordcloud = self.domain_classification(input_text)
        # feature = "\n".join(feature)
        

        return domain_output,domain_xiuzheng_output, xiaofeidu_output,wordcloud, feature, summary

    def build_interface(self):
        with gr.Blocks(title="æŠ€æœ¯é¢†åŸŸåˆ†ç±»å·¥å…·", css=".gradio-container .prose h1, .gradio-container .prose h2, .gradio-container .prose h3 {text-align: center;}", theme=gr.themes.Soft()) as demo:
            gr.Markdown("## ğŸš€ æŠ€æœ¯é¢†åŸŸåˆ†ç±»å·¥å…·")
            gr.Markdown("è¾“å…¥å¼€æºé¡¹ç›®é“¾æ¥ï¼Œæˆ‘ä»¬å°†è¿›è¡Œç‰¹å¾è¯èŒƒå¼æå–ï¼ŒåŠŸèƒ½æ³¨è§£ç”Ÿæˆä»¥åŠæŠ€æœ¯é¢†åŸŸåˆ†ç±»ã€‚")

            with gr.Row():
                self.text_input = gr.Textbox(
                    label="è¾“å…¥å¼€æºé¡¹ç›®é“¾æ¥",
                    placeholder="ç²˜è´´æˆ–è¾“å…¥å¼€æºé¡¹ç›®é“¾æ¥...",
                    lines=8,
                    max_lines=20,
                    interactive=True
                )
            
            self.submit_btn = gr.Button("start", variant="primary")
            self.clear_btn = gr.Button("clear")


            with gr.Tab("æŠ€æœ¯é¢†åŸŸåˆ†ç±»"):
                with gr.Row():
                    with gr.Column(scale=2):
                        self.domain_output = gr.Textbox(label="åˆå§‹å®é¢†åŸŸåˆ†ç±»ç»“æœ")
                        self.domain_xiuzheng_output = gr.Textbox(label="å®é¢†åŸŸåˆ†ç±»ç»“æœ")
                        self.xiaofeidu_output = gr.Textbox(label="ç»†åˆ†é¢†åŸŸåˆ†ç±»ç»“æœ")
                    with gr.Column(scale=1):
                        self.keywords_btn = gr.Button("å®é¢†åŸŸåˆ’åˆ†", variant="primary")
                        self.summary_btn = gr.Button("ç”ŸæˆåŠŸèƒ½æ³¨è§£", variant="primary")
                        self.domain_btn = gr.Button("æŠ€æœ¯é¢†åŸŸåˆ†ç±»", variant="primary")


            with gr.Tab("è¯äº‘å›¾"):
                self.wordcloud_output = gr.Image(label="ç‰¹å¾è¯è¯äº‘", type="filepath")

            with gr.Tab("ç‰¹å¾è¯åˆ—è¡¨"):
                self.keywords_output = gr.Textbox(label="ç‰¹å¾è¯æ‘˜è¦")

            with gr.Tab("æ–‡æœ¬åŠŸèƒ½æ³¨è§£"):
                self.summary_output = gr.Textbox(label="åŠŸèƒ½æ³¨è§£", lines=4)
                
            
            with gr.Row():
                gr.Markdown("### Made by [OpenInsight](https://github.com/whoami648/open_insight)")

            
            # ä¿®æ­£ keywords_btn.click çš„ inputs å‚æ•°
            # åº”è¯¥ä¼ å…¥ gradio ç»„ä»¶è€Œä¸æ˜¯å­—ç¬¦ä¸²
            # è¿™é‡Œå‡è®¾ç‰¹å¾è¯æ‘˜è¦éœ€è¦è¾“å…¥é¡¹ç›®é“¾æ¥
            self.keywords_btn.click(
                fn=self.word_paradigm_generation,
                inputs=self.text_input,
                outputs=[self.domain_output, self.wordcloud_output, self.keywords_output]
            )
            self.summary_btn.click(
                fn=self.function_annotations,
                inputs=self.text_input,
                outputs=self.summary_output
            )
            self.domain_btn.click(
                fn=self.domain_classification,
                inputs=self.text_input,
                outputs=[self.domain_xiuzheng_output, self.xiaofeidu_output, self.keywords_output,self.wordcloud_output]
            )
            self.submit_btn.click(
                fn=self.text_analysis,
                inputs=self.text_input,
                outputs=[self.domain_output,self.domain_xiuzheng_output, self.xiaofeidu_output, self.wordcloud_output, self.keywords_output, self.summary_output]
            )
            #domain_output,domain_xiuzheng_output, xiaofeidu_output,wordcloud_path, feature, summary
            self.clear_btn.click(
                lambda: [None,None, None, None, None, None],
                inputs=None,
                outputs=[self.domain_output,self.domain_xiuzheng_output, self.xiaofeidu_output, self.wordcloud_output, self.keywords_output, self.summary_output]
            )
        return demo

    def launch(self, server_port=8000, share=False):
        self.demo.launch(server_port=server_port, share=share)

if __name__ == "__main__":
    app = TextAnalysisApp()
    app.launch(server_port=8002, share=False)
